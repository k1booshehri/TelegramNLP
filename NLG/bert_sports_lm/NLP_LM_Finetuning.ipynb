{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADKCnENMQdJE"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install tqdm boto3 requests regex sentencepiece sacremoses\n",
        "!pip install pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "u_nYLYAEucNR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import  tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nqMyfhLQvfLk"
      },
      "outputs": [],
      "source": [
        "hotel_df = pd.read_csv('data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icA0x2dsvkfi"
      },
      "outputs": [],
      "source": [
        "hotel_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dCDJWiYdvrf9"
      },
      "outputs": [],
      "source": [
        "hotel_df['REVIEW'] = hotel_df['data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UAX1oxUBASyl"
      },
      "outputs": [],
      "source": [
        "hotel_df['REVIEW'] = hotel_df.REVIEW.str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "EsFeGXrgvtrO"
      },
      "outputs": [],
      "source": [
        "hotel_df['REVIEW'] = hotel_df['REVIEW'].map(lambda k: '[REVIEW] '+str(k))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "K15VAxRwv49Y"
      },
      "outputs": [],
      "source": [
        "changed_text=hotel_df.REVIEW.apply(lambda x:x+\"\\n\"+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oSgYg9hwAfq",
        "outputId": "4bd9e68d-b895-453b-fd90-3cdcc23ab3b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "160748"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "open('data_lm_hotel.txt', \"w\").write(''.join(changed_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HErmibFVwx7D",
        "outputId": "862cb0c0-15e5-4081-cd16-2e6709ae9b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 231508/231508 [00:00<00:00, 26628683.13B/s]\n",
            "Loading Dataset: 1998 lines [00:00, 4445.77 lines/s]\n",
            "Epoch:   0% 0/1 [00:00<?, ?it/s]\n",
            "Document: 100% 999/999 [00:00<00:00, 10020.09it/s]\n",
            "Epoch: 100% 1/1 [00:00<00:00,  9.96it/s]\n"
          ]
        }
      ],
      "source": [
        "!python3 pregenerate_training_data.py --train_corpus data_lm_hotel.txt --bert_model bert-base-uncased --do_lower_case --output_dir training/ --epochs_to_generate 1 --max_seq_len 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q-wxugGxMkx",
        "outputId": "55055590-785a-4a63-f425-5acfc7ae80e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-07 06:58:35,297: device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "2022-07-07 06:58:35,342: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2022-07-07 06:58:35,423: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpetrpbii1\n",
            "\r  0% 0/433 [00:00<?, ?B/s]\r100% 433/433 [00:00<00:00, 635233.87B/s]\n",
            "2022-07-07 06:58:35,457: copying /tmp/tmpetrpbii1 to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-07-07 06:58:35,457: creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-07-07 06:58:35,457: removing temp file /tmp/tmpetrpbii1\n",
            "2022-07-07 06:58:35,457: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-07-07 06:58:35,457: Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2022-07-07 06:58:35,494: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmp2fvfdu89\n",
            "100% 440473133/440473133 [00:06<00:00, 71357277.13B/s]\n",
            "2022-07-07 06:58:41,739: copying /tmp/tmp2fvfdu89 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-07-07 06:58:43,125: creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-07-07 06:58:43,125: removing temp file /tmp/tmp2fvfdu89\n",
            "2022-07-07 06:58:43,176: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-07-07 06:58:57,012: ***** Running training *****\n",
            "2022-07-07 06:58:57,012:   Num examples = 999\n",
            "2022-07-07 06:58:57,012:   Batch size = 16\n",
            "2022-07-07 06:58:57,012:   Num steps = 62\n",
            "finetune_on_pregenerated.py:88: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  input_masks = np.zeros(shape=(num_samples, seq_len), dtype=np.bool)\n",
            "finetune_on_pregenerated.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  segment_ids = np.zeros(shape=(num_samples, seq_len), dtype=np.bool)\n",
            "finetune_on_pregenerated.py:91: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  is_nexts = np.zeros(shape=(num_samples,), dtype=np.bool)\n",
            "2022-07-07 06:58:57,014: Loading training examples for epoch 0\n",
            "Training examples:   0% 0/999 [00:00<?, ?it/s]finetune_on_pregenerated.py:38: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  input_array = np.zeros(max_seq_length, dtype=np.int)\n",
            "finetune_on_pregenerated.py:41: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  mask_array = np.zeros(max_seq_length, dtype=np.bool)\n",
            "finetune_on_pregenerated.py:44: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  segment_array = np.zeros(max_seq_length, dtype=np.bool)\n",
            "finetune_on_pregenerated.py:47: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  lm_label_array = np.full(max_seq_length, dtype=np.int, fill_value=-1)\n",
            "Training examples: 100% 999/999 [00:00<00:00, 11731.28it/s]\n",
            "2022-07-07 06:58:57,099: Loading complete!\n",
            "Epoch 0:   2% 1/63 [00:00<00:29,  2.07it/s, Loss: 17.25792]/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "Epoch 0: 100% 63/63 [00:25<00:00,  2.43it/s, Loss: 5.19670]\n",
            "2022-07-07 06:59:23,034: ** ** * Saving fine-tuned model ** ** * \n"
          ]
        }
      ],
      "source": [
        "!python3 finetune_on_pregenerated.py --pregenerated_data training/ --bert_model bert-base-uncased --do_lower_case --train_batch_size 16  --output_dir finetuned_lm/ --epochs 1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_LM_Finetuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}